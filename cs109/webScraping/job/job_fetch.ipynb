{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/media/zhou/DATA/zhousu/git/github_new/DataLab/cs109/webScraping/job\n",
      "KEYWORD_LIST size: ['Java', 'Backend', 'data', 'architect']\n",
      "EXECLUDE_COMPANY size: ['dfds', 'prodata', 'Systematic', 'test']\n",
      "SLEEP: 6\n",
      "PAGE_SIZE: 5\n",
      "Starting \n",
      "Starting \n",
      "Starting Starting \n",
      "Starting \n",
      "\n",
      "total insert: total insert:  0\n",
      "total insert:  0\n",
      "Exiting \n",
      " 0\n",
      "Exiting \n",
      "Exiting \n",
      "total insert:  0\n",
      "Exiting \n",
      "total insert:  0\n",
      "Exiting \n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "from FetchThread import FetchThread\n",
    "\n",
    "sys.path.append(\"/media/zhou/DATA/zhousu/git/github_new/DataLab/cs109/webScraping/job\")\n",
    "from StackOverflow import StackOverflowJob\n",
    "\n",
    "from LinkedIn import LinkedInJob\n",
    "from ItJobBank import ItJobBankJob\n",
    "from Nordea import NordeaJob\n",
    "from neuvoo import NeuvooJob\n",
    "from JobIndex import JobIndexJob\n",
    "from job import Job\n",
    "\n",
    "import psycopg2\n",
    "\n",
    "import threading\n",
    "\n",
    "\n",
    "EXECLUDE_TITLE = [\"frontend\", \"c#\", \"udvikler\", \"android\", \"analyst\", \"devops\", \"security\", \"sale\",\"microsoft\"]\n",
    "EXECLUDE_COMPANY = [\"dfds\", \"prodata\", \"Systematic\",\"test\"]\n",
    "#KEYWORD_LIST=[\"Java\",\"Data\", \"developer\"]\n",
    "KEYWORD_LIST=[\"Java\", \"Backend\", \"data\", \"architect\"]\n",
    "STACKOVERFLOW_KEYWORD_LIST=[\"Backend\"]\n",
    "SLEEP=6\n",
    "PAGE_SIZE = 5\n",
    "\n",
    "print(\"KEYWORD_LIST size: \" + str(KEYWORD_LIST))\n",
    "print(\"EXECLUDE_COMPANY size: \" + str(EXECLUDE_COMPANY))\n",
    "print(\"SLEEP: \" + str(SLEEP))\n",
    "print(\"PAGE_SIZE: \" + str(PAGE_SIZE))\n",
    "\n",
    "jobs=[Job(), ]\n",
    "\n",
    "jobSet = set([])\n",
    "\n",
    "list1 = [LinkedInJob(), JobIndexJob(), NeuvooJob(), ItJobBankJob(), StackOverflowJob()]\n",
    "list2 = [LinkedInJob(),  JobIndexJob(), NeuvooJob(), ItJobBankJob()]\n",
    "list3 = [ StackOverflowJob()]\n",
    "\n",
    "def fetch_job(jobSet, keyWords, size):\n",
    "    jobSet = jobSet.union(jobSite.get_jobset(keyWords, size, SLEEP))\n",
    "\n",
    "for jobSite in list2:\n",
    "    thread1 = FetchThread(jobSite, KEYWORD_LIST, 5)\n",
    "    thread1.start()\n",
    "\n",
    "for jobSite in list3:\n",
    "    thread1 = FetchThread(jobSite, STACKOVERFLOW_KEYWORD_LIST, 5)\n",
    "    thread1.start()\n",
    "\n",
    "#j.write_file(jobSet, './data/all_jobs'+datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")+'.csv')\n",
    "#print(jobSet)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d1 = 2021-01-08\n",
      "d2 = 2021-01-05\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "import datetime as DT\n",
    "\n",
    "\n",
    "\n",
    "today = date.today()\n",
    "\n",
    "# dd/mm/YY\n",
    "d1 = today.strftime(\"%Y-%m-%d\")\n",
    "print(\"d1 =\", d1)\n",
    "\n",
    "time = '3 days ago'.split()\n",
    "delta = int(time[0])\n",
    "unit = time[1]\n",
    "if unit.startswith(\"day\"):\n",
    "    delta = delta * 24\n",
    "elif unit.startswith(\"week\"):\n",
    "    delta = delta * 24 * 7\n",
    "\n",
    "pub_date = today - DT.timedelta(hours=delta)\n",
    "d1 = pub_date.strftime(\"%Y-%m-%d\")\n",
    "print(\"d2 =\", d1)\n",
    "#time[0]\n",
    "\n",
    "#if time[1] == 'days'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
